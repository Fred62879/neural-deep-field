parent: base.yaml

global:
    use_tqdm: True
    exp_name: 'autodecoder-dz-spectra-pe'
    # log_fname: ''


    tasks: ['generalization']
    tasks: ['generalization_infer','recon_spectra','save_redshift','plot_redshift_est_stats','plot_redshift_residual'] #,'plot_redshift_logits'] #'plot_spectra_latents_pca'

optimizer:
    optimizer_type: 'adam'

    b1: 0.5
    b2: 0.999
    lr: 1e-4
    spectra_latents_lr: 1e-3
    codebook_pretrain_lr: 1e-3
    weight_decay: 1e-5

    sgd_momentum: 0.9

embedder:
    encode_wave: True
    wave_encode_method: positional_encoding
    wave_embed_dim: 16

pretrain:
    generalize_train_first_layer: False

    pretrain_batch_size: 35

    pretrain_use_all_wave: False
    pretrain_num_wave_samples: 100
    pretrain_wave_sample_method: 'uniform_dense'

    spectra_latent_dim: 16
    generalization_max_num_spectra: 100

    load_pretrained_spectra_latents: False
    load_pretrained_spectra_latents_to_gt_bin_only: False
    optimize_gt_bin_only: False
    dont_optimize_gt_bin: False

    pretrain_log_dir: '20240423-204114_decoder_latents_skip_all_layers_True_regularize_spectra_latents_False_decoder_num_hidden_layers_5'
    pretrained_model_name: 'model-ep5000-bch0.pth'

    regularize_spectra_latents: False
    spectra_latents_regu_beta: -1

decoder:
    decoder_batch_norm: False
    decoder_num_hidden_layers: 5
    decoder_hidden_dim: 512
    decoder_skip_layers: []

    decoder_activate_before_latents_skip: False
    decoder_latents_skip_all_layers: True
    decoder_latents_skip_method: 'add'
    decoder_latents_skip_add_conversion_method: 'multi_conversion'

trainer:
    num_epochs: 200
    batch_size: 5500
    log_cli_every: 20
    plot_grad_every: -1
    save_model_every: 20

    plot_l2_loss: True

    apply_gt_redshift: False
    calculate_binwise_spectra_loss: True # brute force, each bin has its own spectra

    # if brute force, we have three choices
    regularize_binwise_spectra_latents: False     # conflicts each other
    optimize_latents_for_each_redshift_bin: True #
    # optimize_one_latent_for_all_redshift_bins:  # hidden, True if the other two False

    calculate_spectra_loss_based_on_optimal_bin: True # only if we use single latent
    calculate_spectra_loss_based_on_top_n_bins: False # only if we use single latent
    num_bins_to_calculate_spectra_loss: 5

    resume_train: False
    resume_log_dir: ''
    resume_model_fname: 'model-ep10000-bch0.pth'

    spectra_loss_cho: ssim1d
    spectra_loss_reduction: mean
    spectra_ssim_loss_filter_size: 9
    spectra_ssim_loss_filter_sigma: 5

infer:
    infer_last_model_only: True

    #infer_log_dir: ''

    infer_selected: False
    pretrain_num_infer_upper_bound: 35
    spectra_inferrence_id_fname: '' #'/redshift/model-0_redshift_outlier_ids.npy'
    infer_outlier_only: True

    pretrain_infer_batch_size: 1
    pretrain_infer_use_all_wave: True
    pretrain_infer_num_wave: 200
    pretrain_infer_wave_sample_method: 'uniform_non_random'

    plot_clipped_spectrum: True
    plot_spectrum_with_loss: False
    plot_spectrum_with_ivar: False
    plot_spectrum_with_lines: True
    plot_spectrum_with_recon: False
    plot_spectrum_color_based_on_loss: False
    plot_spectrum_under_gt_bin: True
    plot_spectrum_under_optimal_wrong_bin: False

    num_spectrum_per_fig: 35
    num_spectrum_per_row: 7

    sanity_check_plot_same_pca_dim_as_pretrain: True
    pretrain_pca_dim_fname: '' #'/latents/2-dim/selected_axes.npy'
    spectra_latents_plot_pca_dim: 2

    log_redshift_est_stats: False
    log_redshift_est_stats_residual_levels: [0.02,0.04,0.08]

spectra_data:
    spectra_cho: v1
    spectra_process_patch_info: False
    spectra_data_sources: [deimos,zcosmos]
    random_permute_source_spectra: True

    spectra_upsample_scale: 10
    convolve_spectra: True
    process_ivar: True
    spectra_smooth_sigma: 15

    num_gt_spectra_upper_bound: 25400
    num_supervision_spectra_upper_bound: 25400

    filter_redshift: False
    filter_redshift_lo: 0.02
    filter_redshift_hi: -1

ablation:
    perform_ablation: False
    ablat_id: 0
    ablat_params: ["spectra_latent_dim","decoder_num_hidden_layers","decoder_hidden_dim"]
    ablat_vals: [[8,16,32],[3,5],[128,256,512]]
    ablat_num_vals: [3,2,3]

    #ablat_hardcode_params: []
    #ablat_hardcode_vals: [[]]
